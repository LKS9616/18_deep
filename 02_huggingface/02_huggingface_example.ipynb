{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텍스트 기반 감정분석\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a7ecef618f4e85abc310cbfaa59ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\80419\\miniforge3\\envs\\lecture_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\80419\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22fe952817554944836a36af00b03c38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fcfe072fef44a5ba9c6831d4aed2c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c0f4d3f4c949b1a8b125f4f8714f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598048329353333}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 모델 가져오기\n",
    "classifier = pipeline('text-classification')\n",
    "\n",
    "# 문제\n",
    "text = \"I've been waiting for a HuggingFace course my whole life.\"\n",
    "\n",
    "classifier(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9516069293022156},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 감정분석\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "classifier(\n",
    "    [\n",
    "        \"I've been wating for a HuggingFace course my whole life.\",\n",
    "        \"I hate this so much!\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 감정분석\n",
    "classifier = pipeline(\"text-classification\", model=\"Minej/bert-base-personality\")\n",
    "\n",
    "classifier(\n",
    "    [\n",
    "        \"I've been wating for a HuggingFace course my whole life.\",\n",
    "        \"I hate this so much!\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 제로샷 분류\n",
    "* Zero-shot : 기계 학습 및 자연어 처리에서 각 개별 작업에 대한 특정 교육 없이 작업을 수행할 수 있는 모델 유형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aedbfb4f59f44839cba9e887b116bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  23%|##3       | 377M/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fddecf3fb4fa4b9eab17810d3d9e494d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22df6d1a680942b184106b9576f2e440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02f3ee3bdede450eac7279c50d7adeb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302daf84b4ab4a12a5baae8e48ff09c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about the Transformers library',\n",
       " 'labels': ['education', 'business', 'cook'],\n",
       " 'scores': [0.8214151263237, 0.10890114307403564, 0.06968369334936142]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# 분석할 문장\n",
    "# sequence_to_classify = \"one day I will see the world\"\n",
    "\n",
    "# 결과로 받을 label들\n",
    "# candidate_labels = ['travel', 'cooking', 'dancing']\n",
    "# classifier(sequence_to_classify, candidate_labels)\n",
    "\n",
    "sequence_to_classify = \"This is a course about the Transformers library\"\n",
    "\n",
    "# 결과로 받을 label들\n",
    "candidate_labels = ['cook', 'business', 'education']\n",
    "classifier(sequence_to_classify, candidate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텍스트 생성 (Text Generation)\n",
    "* 주어진 텍스트 데이터를 기반으로 새로운 텍스트를 생성하는 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to create a virtual machine which will run on your Windows desktop, with the option of any virtual machine having the Windows-like functionality of your Windows machine. Our virtual machine will not have any built-in'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", \"gpt2\")\n",
    "\n",
    "generator(\"In this course, we will teach you how to\", pad_token_id = generator.tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 마스크 채우기 모델\n",
    "* 텍스트에서 일부 단어를 마스크로 대체하고 이를 채우는 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.18409927189350128,\n",
       "  'token': 3299,\n",
       "  'token_str': ' doctor',\n",
       "  'sequence': \"I'm going to hospital and meet a doctor\"},\n",
       " {'score': 0.06829287856817245,\n",
       "  'token': 27321,\n",
       "  'token_str': ' psychiatrist',\n",
       "  'sequence': \"I'm going to hospital and meet a psychiatrist\"},\n",
       " {'score': 0.06475960463285446,\n",
       "  'token': 9008,\n",
       "  'token_str': ' nurse',\n",
       "  'sequence': \"I'm going to hospital and meet a nurse\"},\n",
       " {'score': 0.05908999219536781,\n",
       "  'token': 16308,\n",
       "  'token_str': ' surgeon',\n",
       "  'sequence': \"I'm going to hospital and meet a surgeon\"},\n",
       " {'score': 0.05502228066325188,\n",
       "  'token': 1441,\n",
       "  'token_str': ' friend',\n",
       "  'sequence': \"I'm going to hospital and meet a friend\"},\n",
       " {'score': 0.03473343700170517,\n",
       "  'token': 12443,\n",
       "  'token_str': ' stranger',\n",
       "  'sequence': \"I'm going to hospital and meet a stranger\"},\n",
       " {'score': 0.032203420996665955,\n",
       "  'token': 18931,\n",
       "  'token_str': ' therapist',\n",
       "  'sequence': \"I'm going to hospital and meet a therapist\"},\n",
       " {'score': 0.02806202881038189,\n",
       "  'token': 26565,\n",
       "  'token_str': ' dentist',\n",
       "  'sequence': \"I'm going to hospital and meet a dentist\"},\n",
       " {'score': 0.02702230028808117,\n",
       "  'token': 1816,\n",
       "  'token_str': ' girl',\n",
       "  'sequence': \"I'm going to hospital and meet a girl\"},\n",
       " {'score': 0.025335688143968582,\n",
       "  'token': 3186,\n",
       "  'token_str': ' patient',\n",
       "  'sequence': \"I'm going to hospital and meet a patient\"},\n",
       " {'score': 0.014181137084960938,\n",
       "  'token': 2173,\n",
       "  'token_str': ' guy',\n",
       "  'sequence': \"I'm going to hospital and meet a guy\"},\n",
       " {'score': 0.01284089870750904,\n",
       "  'token': 693,\n",
       "  'token_str': ' woman',\n",
       "  'sequence': \"I'm going to hospital and meet a woman\"},\n",
       " {'score': 0.010980658233165741,\n",
       "  'token': 6429,\n",
       "  'token_str': ' lady',\n",
       "  'sequence': \"I'm going to hospital and meet a lady\"},\n",
       " {'score': 0.009920519776642323,\n",
       "  'token': 9896,\n",
       "  'token_str': ' colleague',\n",
       "  'sequence': \"I'm going to hospital and meet a colleague\"},\n",
       " {'score': 0.008793746121227741,\n",
       "  'token': 313,\n",
       "  'token_str': ' man',\n",
       "  'sequence': \"I'm going to hospital and meet a man\"},\n",
       " {'score': 0.008405908942222595,\n",
       "  'token': 6096,\n",
       "  'token_str': ' girlfriend',\n",
       "  'sequence': \"I'm going to hospital and meet a girlfriend\"},\n",
       " {'score': 0.008208610117435455,\n",
       "  'token': 19902,\n",
       "  'token_str': ' psychologist',\n",
       "  'sequence': \"I'm going to hospital and meet a psychologist\"},\n",
       " {'score': 0.00796552561223507,\n",
       "  'token': 6857,\n",
       "  'token_str': ' specialist',\n",
       "  'sequence': \"I'm going to hospital and meet a specialist\"},\n",
       " {'score': 0.007248295471072197,\n",
       "  'token': 6578,\n",
       "  'token_str': ' boyfriend',\n",
       "  'sequence': \"I'm going to hospital and meet a boyfriend\"},\n",
       " {'score': 0.0071894205175340176,\n",
       "  'token': 2143,\n",
       "  'token_str': ' boy',\n",
       "  'sequence': \"I'm going to hospital and meet a boy\"}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "unmasker = pipeline('fill-mask', 'distilroberta-base')\n",
    "\n",
    "unmasker(\"i want to go <mask>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2320a22ac5f04ad0a676f4e8f2ffc0a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\80419\\miniforge3\\envs\\lecture_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\80419\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39348679ac8344e2b7ed62c4f70a61d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d9a6601838649eeaaa63641d834521d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af919d2096224443aba197bb52561d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52046a47bfbd4d85b7e75c0778a6aa75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.10138595849275589,\n",
       "  'token': 4827,\n",
       "  'token_str': 'fashion',\n",
       "  'sequence': \"hello i ' m a fashion model\"},\n",
       " {'score': 0.052310675382614136,\n",
       "  'token': 2047,\n",
       "  'token_str': 'new',\n",
       "  'sequence': \"hello i ' m a new model\"},\n",
       " {'score': 0.03911250829696655,\n",
       "  'token': 2944,\n",
       "  'token_str': 'model',\n",
       "  'sequence': \"hello i ' m a model model\"},\n",
       " {'score': 0.03866786137223244,\n",
       "  'token': 3565,\n",
       "  'token_str': 'super',\n",
       "  'sequence': \"hello i ' m a super model\"},\n",
       " {'score': 0.032727789133787155,\n",
       "  'token': 2535,\n",
       "  'token_str': 'role',\n",
       "  'sequence': \"hello i ' m a role model\"}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "unmasker = pipeline('fill-mask', model = 'bert-base-uncased')\n",
    "\n",
    "unmasker(\"hello i'm a [MASK] model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c12e0756f749b98c3333f475d77708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\80419\\miniforge3\\envs\\lecture_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\80419\\.cache\\huggingface\\hub\\models--FacebookAI--xlm-roberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfcdbe7330464df5b8b43530329016ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at FacebookAI/xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a1e92b27fc649739905126106914e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9198754307e74258b5ef239c74aa4fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe495c9ce174f9b8673cdde79147ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.05429058149456978,\n",
       "  'token': 81053,\n",
       "  'token_str': '자동차',\n",
       "  'sequence': '안녕하세요? 나는 자동차 모델입니다.'},\n",
       " {'score': 0.03555170074105263,\n",
       "  'token': 56575,\n",
       "  'token_str': 'Fashion',\n",
       "  'sequence': '안녕하세요? 나는 Fashion 모델입니다.'},\n",
       " {'score': 0.030248744413256645,\n",
       "  'token': 53226,\n",
       "  'token_str': '광고',\n",
       "  'sequence': '안녕하세요? 나는 광고 모델입니다.'},\n",
       " {'score': 0.024159586057066917,\n",
       "  'token': 54543,\n",
       "  'token_str': 'fashion',\n",
       "  'sequence': '안녕하세요? 나는 fashion 모델입니다.'},\n",
       " {'score': 0.02254818007349968,\n",
       "  'token': 26084,\n",
       "  'token_str': '사진',\n",
       "  'sequence': '안녕하세요? 나는 사진 모델입니다.'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"fill-mask\", model=\"FacebookAI/xlm-roberta-base\")\n",
    "\n",
    "pipe(\"안녕하세요? 나는 <mask> 모델입니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 개체명 인식\n",
    "\n",
    "* NER(Name Entity Recognition)\n",
    "* 텍스트에서 사람, 위치, 조직 등의 객체명을 인식하는 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 문장이 주어지고, 문자에서 사람이름을 판단하는 task\n",
    "ner = pipeline(\"ner\", \"dbmdz/bert-large-cased-finetuned-conll03-english\", grouped_entities=True)  # 개체명 인식\n",
    "ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "질의응답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "question_answerer = pipeline(\"question-answering\", \"distilbert-base-cased-distilled-squad\")  # 질의 응답\n",
    "question_answerer(\n",
    "    question=\"Where do I work?\",\n",
    "    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca96ccfe4c54db9a142fdfea763b177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\80419\\miniforge3\\envs\\lecture_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\80419\\.cache\\huggingface\\hub\\models--sshleifer--distilbart-cnn-12-6. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5882d9420e03410883fe049efd2431fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cdd41218dc249b5baa21b7de19f685e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb6e3edd7e5546bd8eec4b1d06ddfd36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3d621251424a0bafe1e413d4a476d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' The number of engineering graduates in the U.S. has declined in traditional engineering disciplines in recent years . China and India graduate six and eight times as many traditional engineers as does the United States . Rapidly developing economies in Europe and Asia continue to encourage and advance the teaching of engineering .'}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "summarizer = pipeline(\"summarization\",\"sshleifer/distilbart-cnn-12-6\")  # 요약\n",
    "summarizer(\n",
    "    \"\"\"\n",
    "    America has changed dramatically during recent years. Not only has the number of\n",
    "    graduates in traditional engineering disciplines such as mechanical, civil,\n",
    "    electrical, chemical, and aeronautical engineering declined, but in most of\n",
    "    the premier American universities engineering curricula now concentrate on\n",
    "    and encourage largely the study of engineering science. As a result, there\n",
    "    are declining offerings in engineering subjects dealing with infrastructure,\n",
    "    the environment, and related issues, and greater concentration on high\n",
    "    technology subjects, largely supporting increasingly complex scientific\n",
    "    developments. While the latter is important, it should not be at the expense\n",
    "    of more traditional engineering.\n",
    " \n",
    "    Rapidly developing economies such as China and India, as well as other\n",
    "    industrial countries in Europe and Asia, continue to encourage and advance\n",
    "    the teaching of engineering. Both China and India, respectively, graduate\n",
    "    six and eight times as many traditional engineers as does the United States.\n",
    "    Other industrial countries at minimum maintain their output, while America\n",
    "    suffers an increasingly serious decline in the number of engineering graduates\n",
    "    and a lack of well-educated engineers.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sacremoses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지를 설명하는 텍스트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "imagetotext = pipeline(\"image-to-text\", \"ydshieh/vit-gpt2-coco-en\")\n",
    "imagetotext(\"https://huggingface.co/datasets/Narsil/image_dummy/resolve/main/parrots.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "imagetotext = pipeline(\"image-to-text\", \"ydshieh/vit-gpt2-coco-en\")\n",
    "imagetotext(\"https://huggingface.co/datasets/Narsil/image_dummy/resolve/main/parrots.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "url = 'https://huggingface.co/datasets/Narsil/image_dummy/resolve/main/parrots.png'\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"image-classification\", model=\"google/vit-base-patch16-224\")\n",
    "\n",
    "outputs = pipe(image)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zero-shot 이미지 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I have a problem with my iphone that needs to be resolved asap!!',\n",
       " 'labels': ['urgent', 'phone', 'computer', 'not urgent', 'tablet'],\n",
       " 'scores': [0.5036352872848511,\n",
       "  0.47880008816719055,\n",
       "  0.01260011363774538,\n",
       "  0.002655791351571679,\n",
       "  0.0023087477311491966]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "checkpoint = \"openai/clip-vit-large-patch14\"\n",
    "detector = pipeline(model=checkpoint, task=\"zero-shot-image-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = \"https://unsplash.com/photos/g8oS8-82DxI/download?ixid=MnwxMjA3fDB8MXx0b3BpY3x8SnBnNktpZGwtSGt8fHx8fDJ8fDE2NzgxMDYwODc&force=true&w=640\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = detector(image, candidate_labels=[\"food\", \"bird\", \"seagull\", \"owl\"])\n",
    "\n",
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
